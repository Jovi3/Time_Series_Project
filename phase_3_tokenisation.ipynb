{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Gruver-style dataset with 5064 samples.\n",
      "Saved Delphyne-style dataset with 5064 samples.\n",
      "\n",
      "Example Gruver-style sample:\n",
      "{\n",
      "  \"input_text\": \"0 . 0 1 3 8 9 8 | 0 . 0 1 5 6 2 2 | 0 . 0 1 4 1 4 | 0 . 0 1 6 3 1 4 | 0 . 0 1 4 3 4 4 | 0 . 0 1 4 1 9 5 | 0 . 0 2 9 9 4 | 0 . 0 0 1 0 0 9 | - 0 . 0 0 0 1 6 5 | 0 . 0 0 0 7 8 6 | - 0 . 0 0 3 9 6 7 | 0 . 0 0 1 4 9 9 | 0 . 0 0 0 7 8 3 | - 0 . 0 0 5 3 1 | 0 . 0 1 0 8 5 3 | 0 . 0 1 2 2 8 5 | 0 . 0 1 1 3 6 6 | 0 . 0 1 1 8 2 7 | 0 . 0 1 2 6 7 3 | 0 . 0 1 1 3 2 4 | 0 . 0 1 5 3 3 1 | 0 . 0 0 3 8 9 7 | 0 . 0 0 5 7 0 2 | 0 . 0 0 3 9 3 6 | 0 . 0 0 3 3 9 2 | 0 . 0 0 5 6 1 7 | 0 . 0 0 3 9 2 1 | 0 . 0 0 7 4 8 2 | 0 . 0 0 7 3 9 9 | 0 . 0 0 9 4 7 9 | 0 . 0 0 7 2 2 2 | 0 . 0 0 6 6 9 9 | 0 . 0 0 8 9 6 6 | 0 . 0 0 7 5 3 | 0 . 0 2 5 7 5 9 | - 0 . 0 0 1 1 1 4 | 0 . 0 0 1 4 3 4 | - 0 . 0 0 0 6 6 6 | - 0 . 0 0 0 2 1 | 0 . 0 0 0 3 8 8 | - 0 . 0 0 0 8 4 2 | 0 . 0 1 0 5 6 7 | - 0 . 0 0 0 3 4 5 | - 0 . 0 0 2 5 1 1 | - 0 . 0 0 0 4 3 6 | - 0 . 0 0 2 2 7 9 | - 0 . 0 0 0 4 3 7 | - 0 . 0 0 0 4 0 9 | - 0 . 0 1 1 8 1 2 | 0 . 0 0 1 6 6 2 | 0 . 0 0 3 8 1 | 0 . 0 0 1 6 1 5 | 0 . 0 0 5 5 | 0 . 0 0 2 3 7 9 | 0 . 0 0 1 6 8 6 | 0 . 0 0 9 6 0 2 | 0 . 0 0 4 7 1 1 | 0 . 0 0 4 9 6 9 | 0 . 0 0 4 9 4 | 0 . 0 0 5 5 8 9\",\n",
      "  \"target_text\": \"0 . 0 0 5 1 8 4\"\n",
      "}\n",
      "\n",
      "Example Delphyne-style sample:\n",
      "{\n",
      "  \"input_text\": \"0.013898 0.015622 0.01414 0.016314 0.014344 0.014195 0.02994 0.001009 -0.000165 0.000786 -0.003967 0.001499 0.000783 -0.00531 0.010853 0.012285 0.011366 0.011827 0.012673 0.011324 0.015331 0.003897 0.005702 0.003936 0.003392 0.005617 0.003921 0.007482 0.007399 0.009479 0.007222 0.006699 0.008966 0.00753 0.025759 -0.001114 0.001434 -0.000666 -0.00021 0.000388 -0.000842 0.010567 -0.000345 -0.002511 -0.000436 -0.002279 -0.000437 -0.000409 -0.011812 0.001662 0.00381 0.001615 0.0055 0.002379 0.001686 0.009602 0.004711 0.004969 0.00494 0.005589\",\n",
      "  \"target_text\": \"0.005184\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# ============================\n",
    "# LOAD RETURN SERIES\n",
    "# ============================\n",
    "\n",
    "df = pd.read_csv(\"market_features_master.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "# Select the return columns for LLM training\n",
    "return_cols = [\n",
    "    \"SP500_ret\", \"NASDAQ_ret\", \"SPY_ret\", \n",
    "    \"QQQ_ret\", \"VTI_ret\", \"IVV_ret\", \"ARKK_ret\"\n",
    "]\n",
    "\n",
    "# Combine all returns into a single long sequence (as in Gruver/Delphyne)\n",
    "series = df[return_cols].stack().dropna()\n",
    "values = series.values  # numpy array of floats\n",
    "\n",
    "# ============================\n",
    "# PARAMETERS\n",
    "# ============================\n",
    "\n",
    "WINDOW = 60   # past 60 timesteps → predict next\n",
    "\n",
    "\n",
    "# ============================\n",
    "# DIGIT-LEVEL TOKENIZER (GRUVER)\n",
    "# ============================\n",
    "\n",
    "def digit_tokenize(x):\n",
    "    \"\"\"\n",
    "    Convert numeric value into digit tokens:\n",
    "    0.0123 → \"0 . 0 1 2 3\"\n",
    "    -0.5   → \"- . 5\"\n",
    "    \"\"\"\n",
    "    s = \"{:.6f}\".format(x)   # fixed length\n",
    "    s = s.rstrip(\"0\")        # remove trailing zeros\n",
    "    if s.endswith(\".\"):\n",
    "        s += \"0\"\n",
    "\n",
    "    tokens = []\n",
    "    for ch in s:\n",
    "        if ch == '.':\n",
    "            tokens.append(\".\")\n",
    "        elif ch == '-':\n",
    "            tokens.append(\"-\")\n",
    "        else:\n",
    "            tokens.append(ch)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "# ============================\n",
    "# BUILD DATASET 1 (GRUVER)\n",
    "# ============================\n",
    "\n",
    "gruver_samples = []\n",
    "\n",
    "for i in range(len(values) - WINDOW):\n",
    "    input_seq = values[i : i + WINDOW]\n",
    "    target = values[i + WINDOW]\n",
    "\n",
    "    # Tokenize each element\n",
    "    tokenized_input = \" | \".join(digit_tokenize(v) for v in input_seq)\n",
    "    tokenized_target = digit_tokenize(target)\n",
    "\n",
    "    gruver_samples.append({\n",
    "        \"input_text\": tokenized_input,\n",
    "        \"target_text\": tokenized_target\n",
    "    })\n",
    "\n",
    "# Save\n",
    "with open(\"dataset_gruver_digit.jsonl\", \"w\") as f:\n",
    "    for item in gruver_samples:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "print(f\"Saved Gruver-style dataset with {len(gruver_samples)} samples.\")\n",
    "\n",
    "\n",
    "# ============================\n",
    "# BUILD DATASET 2 (DELPHYNE)\n",
    "# ============================\n",
    "\n",
    "def numeric_tokenize(x):\n",
    "    \"\"\"\n",
    "    Convert number into a single text token:\n",
    "    0.0123 → \"0.0123\"\n",
    "    \"\"\"\n",
    "    return \"{:.6f}\".format(x).rstrip(\"0\").rstrip(\".\")\n",
    "\n",
    "\n",
    "delphyne_samples = []\n",
    "\n",
    "for i in range(len(values) - WINDOW):\n",
    "    input_seq = values[i : i + WINDOW]\n",
    "    target = values[i + WINDOW]\n",
    "\n",
    "    # Tokenize numerically\n",
    "    input_str = \" \".join(numeric_tokenize(v) for v in input_seq)\n",
    "    target_str = numeric_tokenize(target)\n",
    "\n",
    "    delphyne_samples.append({\n",
    "        \"input_text\": input_str,\n",
    "        \"target_text\": target_str\n",
    "    })\n",
    "\n",
    "# Save\n",
    "with open(\"dataset_delphyne_numeric.jsonl\", \"w\") as f:\n",
    "    for item in delphyne_samples:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "print(f\"Saved Delphyne-style dataset with {len(delphyne_samples)} samples.\")\n",
    "\n",
    "\n",
    "# ============================\n",
    "# PREVIEW SAMPLES\n",
    "# ============================\n",
    "\n",
    "print(\"\\nExample Gruver-style sample:\")\n",
    "print(json.dumps(gruver_samples[0], indent=2))\n",
    "\n",
    "print(\"\\nExample Delphyne-style sample:\")\n",
    "print(json.dumps(delphyne_samples[0], indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "758b54b07f4628f2981a93ec2fa893cf8f1006e199b2e47f7b9610a507fb2008"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

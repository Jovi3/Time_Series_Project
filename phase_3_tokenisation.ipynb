{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SP500_ret...\n",
      "  ✓ Saved dataset_gruver_SP500_ret.jsonl  (1702 samples)\n",
      "  ✓ Saved dataset_delphyne_SP500_ret.jsonl  (1702 samples)\n",
      "\n",
      "Example Gruver-style sample for SP500_ret:\n",
      "{\n",
      "  \"input_text\": \"- 0 1 8 2 7 8 | - 0 0 8 8 9 3 | 0 1 1 6 3 0 | 0 1 7 8 8 8 | - 0 0 8 4 0 4 | - 0 0 8 0 9 4 | - 0 0 2 5 7 9 | - 0 0 5 8 1 3 | - 0 0 9 2 4 8 | 0 1 3 4 2 4 | 0 0 1 5 5 0 | 0 0 4 7 3 2 | 0 1 5 2 7 0 | - 0 0 5 4 9 2 | 0 0 2 5 6 8 | - 0 1 3 3 8 8 | - 0 1 3 4 9 6 | 0 0 9 5 3 5 | - 0 1 2 9 9 2 | 0 1 2 9 6 2 | 0 1 4 4 3 9 | - 0 0 4 1 5 6 | 0 1 0 2 9 1 | - 0 0 3 4 1 8 | - 0 0 4 2 4 7 | 0 1 0 6 7 6 | - 0 0 0 0 2 9 | 0 0 9 6 4 5 | 0 0 4 0 7 5 | 0 0 1 5 9 8 | - 0 0 0 3 1 4 | - 0 0 1 0 6 2 | 0 0 6 1 2 7 | - 0 0 0 3 0 3 | 0 0 2 7 5 9 | - 0 0 0 7 6 6 | - 0 0 1 4 7 6 | - 0 0 2 9 5 6 | 0 0 6 1 2 5 | - 0 0 4 5 3 9 | - 0 0 4 3 8 9 | 0 0 1 1 9 6 | - 0 1 4 1 7 4 | 0 0 3 9 4 4 | - 0 1 6 9 6 1 | - 0 0 1 9 1 8 | 0 1 2 6 0 1 | - 0 0 6 0 7 5 | 0 1 3 5 3 4 | - 0 0 3 3 2 0 | 0 1 2 1 5 8 | - 0 0 4 8 7 3 | 0 0 9 0 1 3 | - 0 0 1 7 4 6 | - 0 0 6 1 3 9 | - 0 1 4 5 5 9 | - 0 0 2 3 7 7 | 0 0 2 3 6 9 | 0 1 2 2 3 7 | - 0 0 8 7 9 6\",\n",
      "  \"target_text\": \"- 0 0 3 9 6 5\"\n",
      "}\n",
      "\n",
      "Example Delphyne-style sample for SP500_ret:\n",
      "{\n",
      "  \"input_text\": \"-0.018278 -0.008893 0.01163 0.017888 -0.008404 -0.008094 -0.002579 -0.005813 -0.009248 0.013424 0.00155 0.004732 0.01527 -0.005492 0.002568 -0.013388 -0.013496 0.009535 -0.012992 0.012962 0.014439 -0.004156 0.010291 -0.003418 -0.004247 0.010676 -0.000029 0.009645 0.004075 0.001598 -0.000314 -0.001062 0.006127 -0.000303 0.002759 -0.000766 -0.001476 -0.002956 0.006125 -0.004539 -0.004389 0.001196 -0.014174 0.003944 -0.016961 -0.001918 0.012601 -0.006075 0.013534 -0.00332 0.012158 -0.004873 0.009013 -0.001746 -0.006139 -0.014559 -0.002377 0.002369 0.012237 -0.008796\",\n",
      "  \"target_text\": \"-0.003965\"\n",
      "}\n",
      "Processing NASDAQ_ret...\n",
      "  ✓ Saved dataset_gruver_NASDAQ_ret.jsonl  (1702 samples)\n",
      "  ✓ Saved dataset_delphyne_NASDAQ_ret.jsonl  (1702 samples)\n",
      "\n",
      "Example Gruver-style sample for NASDAQ_ret:\n",
      "{\n",
      "  \"input_text\": \"- 0 1 5 7 0 6 | - 0 1 2 8 5 9 | 0 1 2 5 7 0 | 0 1 8 4 3 2 | - 0 0 6 7 8 2 | - 0 0 8 3 6 7 | - 0 0 0 6 8 8 | - 0 0 4 7 5 8 | - 0 1 4 7 6 5 | 0 1 3 9 0 6 | 0 0 4 4 1 7 | 0 0 2 7 0 0 | 0 1 7 7 7 9 | 0 0 1 5 7 5 | 0 0 2 9 1 7 | - 0 1 8 9 1 5 | - 0 0 9 2 9 4 | 0 0 9 7 9 3 | - 0 1 0 2 8 5 | 0 0 8 9 4 2 | 0 1 0 9 1 6 | - 0 0 2 3 3 5 | 0 1 0 2 6 1 | - 0 0 4 3 4 4 | - 0 0 3 8 7 6 | 0 1 3 0 4 1 | 0 0 2 8 2 8 | 0 1 1 7 5 3 | 0 0 7 4 5 8 | 0 0 1 1 1 0 | 0 0 1 4 4 7 | 0 0 3 7 3 8 | 0 0 6 3 5 0 | 0 0 1 0 0 9 | 0 0 1 4 4 1 | - 0 0 0 1 9 7 | 0 0 4 1 7 7 | - 0 0 4 8 8 4 | 0 0 8 9 8 0 | - 0 0 5 6 3 1 | - 0 0 2 5 6 2 | 0 0 3 1 5 5 | - 0 1 1 1 2 6 | 0 0 3 0 5 8 | - 0 1 6 7 2 2 | - 0 0 2 0 2 7 | 0 0 8 9 3 8 | - 0 0 4 4 0 0 | 0 1 1 8 5 4 | 0 0 1 6 0 7 | 0 0 9 1 9 5 | 0 0 1 9 1 7 | 0 0 6 8 1 8 | - 0 0 3 0 7 4 | - 0 0 3 2 4 1 | - 0 2 3 6 6 7 | - 0 0 2 6 9 9 | 0 0 5 7 2 9 | 0 1 1 4 9 4 | - 0 0 9 4 1 1\",\n",
      "  \"target_text\": \"- 0 0 4 2 1 4\"\n",
      "}\n",
      "\n",
      "Example Delphyne-style sample for NASDAQ_ret:\n",
      "{\n",
      "  \"input_text\": \"-0.015706 -0.012859 0.01257 0.018432 -0.006782 -0.008367 -0.000688 -0.004758 -0.014765 0.013906 0.004417 0.0027 0.017779 0.001575 0.002917 -0.018915 -0.009294 0.009793 -0.010285 0.008942 0.010916 -0.002335 0.010261 -0.004344 -0.003876 0.013041 0.002828 0.011753 0.007458 0.00111 0.001447 0.003738 0.00635 0.001009 0.001441 -0.000197 0.004177 -0.004884 0.00898 -0.005631 -0.002562 0.003155 -0.011126 0.003058 -0.016722 -0.002027 0.008938 -0.0044 0.011854 0.001607 0.009195 0.001917 0.006818 -0.003074 -0.003241 -0.023667 -0.002699 0.005729 0.011494 -0.009411\",\n",
      "  \"target_text\": \"-0.004214\"\n",
      "}\n",
      "Processing SPY_ret...\n",
      "  ✓ Saved dataset_gruver_SPY_ret.jsonl  (1702 samples)\n",
      "  ✓ Saved dataset_delphyne_SPY_ret.jsonl  (1702 samples)\n",
      "\n",
      "Example Gruver-style sample for SPY_ret:\n",
      "{\n",
      "  \"input_text\": \"- 0 1 8 0 6 0 | - 0 0 9 4 1 9 | 0 1 2 4 6 1 | 0 1 7 7 4 5 | - 0 0 8 0 1 4 | - 0 0 7 8 3 4 | - 0 0 2 8 1 2 | - 0 0 6 0 3 7 | - 0 0 9 1 6 1 | 0 1 3 1 1 4 | 0 0 2 1 3 3 | 0 0 5 0 4 8 | 0 1 4 8 7 1 | - 0 0 5 4 8 3 | 0 0 2 3 4 2 | - 0 1 3 1 9 0 | - 0 1 2 8 2 4 | 0 0 9 2 4 4 | - 0 1 2 5 7 6 | 0 1 2 3 8 5 | 0 1 4 4 6 1 | - 0 0 3 8 0 8 | 0 1 0 0 9 5 | - 0 0 2 7 6 5 | - 0 0 4 4 7 6 | 0 1 0 6 5 4 | 0 0 0 5 8 0 | 0 0 9 6 1 7 | 0 0 4 1 1 6 | 0 0 1 5 7 3 | 0 0 0 0 9 5 | - 0 0 0 7 1 4 | 0 0 6 0 0 0 | - 0 0 0 1 4 2 | 0 0 2 8 4 1 | - 0 0 0 8 5 0 | - 0 0 1 1 8 1 | - 0 0 3 4 0 6 | 0 0 6 3 1 4 | - 0 0 4 1 0 4 | - 0 0 4 2 1 6 | 0 0 1 0 9 4 | - 0 1 4 0 6 5 | 0 0 4 1 4 4 | - 0 1 6 2 2 2 | - 0 0 2 3 4 2 | 0 1 2 7 1 4 | - 0 0 6 1 3 3 | 0 1 3 3 6 1 | - 0 0 2 9 7 2 | 0 1 2 0 2 2 | - 0 0 4 5 6 2 | 0 0 8 8 2 7 | - 0 0 1 9 4 9 | - 0 0 5 6 1 9 | - 0 1 4 6 5 4 | - 0 0 2 3 8 2 | 0 0 2 2 9 0 | 0 1 2 2 0 0 | - 0 0 8 7 3 9\",\n",
      "  \"target_text\": \"- 0 0 3 5 3 7\"\n",
      "}\n",
      "\n",
      "Example Delphyne-style sample for SPY_ret:\n",
      "{\n",
      "  \"input_text\": \"-0.01806 -0.009419 0.012461 0.017745 -0.008014 -0.007834 -0.002812 -0.006037 -0.009161 0.013114 0.002133 0.005048 0.014871 -0.005483 0.002342 -0.01319 -0.012824 0.009244 -0.012576 0.012385 0.014461 -0.003808 0.010095 -0.002765 -0.004476 0.010654 0.00058 0.009617 0.004116 0.001573 0.000095 -0.000714 0.006 -0.000142 0.002841 -0.00085 -0.001181 -0.003406 0.006314 -0.004104 -0.004216 0.001094 -0.014065 0.004144 -0.016222 -0.002342 0.012714 -0.006133 0.013361 -0.002972 0.012022 -0.004562 0.008827 -0.001949 -0.005619 -0.014654 -0.002382 0.00229 0.0122 -0.008739\",\n",
      "  \"target_text\": \"-0.003537\"\n",
      "}\n",
      "Processing QQQ_ret...\n",
      "  ✓ Saved dataset_gruver_QQQ_ret.jsonl  (1702 samples)\n",
      "  ✓ Saved dataset_delphyne_QQQ_ret.jsonl  (1702 samples)\n",
      "\n",
      "Example Gruver-style sample for QQQ_ret:\n",
      "{\n",
      "  \"input_text\": \"- 0 1 4 6 6 9 | - 0 1 3 4 0 8 | 0 1 2 8 9 1 | 0 1 9 1 4 0 | - 0 0 6 5 8 3 | - 0 1 0 4 2 7 | - 0 0 0 2 9 6 | - 0 0 5 5 1 6 | - 0 1 2 9 7 5 | 0 1 1 7 4 1 | 0 0 7 9 3 5 | 0 0 5 1 1 7 | 0 1 8 5 0 4 | 0 0 2 2 1 1 | - 0 0 1 1 5 1 | - 0 2 5 9 2 7 | - 0 0 5 1 2 6 | 0 0 9 6 1 2 | - 0 0 7 7 5 4 | 0 0 8 7 0 5 | 0 0 9 6 0 9 | - 0 0 0 8 7 4 | 0 0 8 6 5 2 | - 0 0 6 0 7 2 | - 0 0 3 1 9 9 | 0 1 5 5 6 4 | 0 0 3 6 4 0 | 0 1 1 6 4 4 | 0 0 8 5 8 5 | 0 0 0 9 3 5 | 0 0 1 4 0 2 | 0 0 4 9 4 6 | 0 0 6 6 8 6 | 0 0 1 0 1 5 | 0 0 0 7 3 7 | - 0 0 2 4 8 6 | 0 0 5 0 7 7 | - 0 0 4 4 0 8 | 0 0 9 0 4 0 | - 0 0 4 6 6 3 | - 0 0 3 8 5 8 | 0 0 1 7 5 2 | - 0 1 1 3 2 2 | 0 0 2 8 8 6 | - 0 1 8 5 6 7 | - 0 0 5 7 7 0 | 0 0 6 5 6 4 | - 0 0 4 3 4 8 | 0 1 2 9 1 1 | 0 0 1 5 9 3 | 0 0 9 8 2 5 | 0 0 1 4 8 3 | 0 0 6 4 7 3 | - 0 0 1 9 3 5 | - 0 0 3 6 0 0 | - 0 2 2 8 8 5 | - 0 0 3 4 1 4 | 0 0 3 9 9 6 | 0 1 1 4 6 7 | - 0 1 0 5 8 7\",\n",
      "  \"target_text\": \"- 0 0 5 2 0 9\"\n",
      "}\n",
      "\n",
      "Example Delphyne-style sample for QQQ_ret:\n",
      "{\n",
      "  \"input_text\": \"-0.014669 -0.013408 0.012891 0.01914 -0.006583 -0.010427 -0.000296 -0.005516 -0.012975 0.011741 0.007935 0.005117 0.018504 0.002211 -0.001151 -0.025927 -0.005126 0.009612 -0.007754 0.008705 0.009609 -0.000874 0.008652 -0.006072 -0.003199 0.015564 0.00364 0.011644 0.008585 0.000935 0.001402 0.004946 0.006686 0.001015 0.000737 -0.002486 0.005077 -0.004408 0.00904 -0.004663 -0.003858 0.001752 -0.011322 0.002886 -0.018567 -0.00577 0.006564 -0.004348 0.012911 0.001593 0.009825 0.001483 0.006473 -0.001935 -0.0036 -0.022885 -0.003414 0.003996 0.011467 -0.010587\",\n",
      "  \"target_text\": \"-0.005209\"\n",
      "}\n",
      "Processing VTI_ret...\n",
      "  ✓ Saved dataset_gruver_VTI_ret.jsonl  (1702 samples)\n",
      "  ✓ Saved dataset_delphyne_VTI_ret.jsonl  (1702 samples)\n",
      "\n",
      "Example Gruver-style sample for VTI_ret:\n",
      "{\n",
      "  \"input_text\": \"- 0 1 7 1 8 2 | - 0 0 9 7 9 9 | 0 1 1 9 3 3 | 0 1 7 6 4 0 | - 0 0 8 2 9 0 | - 0 0 7 1 2 4 | - 0 0 2 2 9 6 | - 0 0 5 4 6 6 | - 0 1 0 1 2 5 | 0 1 3 2 4 8 | 0 0 1 4 4 2 | 0 0 4 5 1 2 | 0 1 5 1 9 5 | - 0 0 4 5 1 9 | 0 0 4 1 6 1 | - 0 1 1 6 7 7 | - 0 1 3 5 3 0 | 0 0 9 5 6 3 | - 0 1 3 5 8 6 | 0 1 1 2 5 1 | 0 1 5 3 4 7 | - 0 0 3 4 9 5 | 0 1 0 9 9 6 | - 0 0 3 0 0 1 | - 0 0 4 9 8 4 | 0 1 0 2 0 8 | 0 0 0 4 6 8 | 0 0 9 6 3 2 | 0 0 4 7 2 4 | 0 0 1 5 6 7 | 0 0 0 5 5 2 | - 0 0 0 2 7 6 | 0 0 5 6 1 3 | - 0 0 0 0 9 1 | 0 0 2 2 8 8 | - 0 0 0 3 6 5 | - 0 0 0 6 3 9 | - 0 0 3 5 6 5 | 0 0 6 1 4 6 | - 0 0 4 1 0 3 | - 0 0 4 0 2 8 | 0 0 1 5 6 3 | - 0 1 3 8 5 7 | 0 0 3 7 2 2 | - 0 1 5 2 0 5 | - 0 0 0 7 5 3 | 0 1 2 5 3 1 | - 0 0 5 5 8 3 | 0 1 2 5 3 9 | - 0 0 1 9 4 1 | 0 1 1 4 8 1 | - 0 0 3 5 7 0 | 0 0 8 3 6 0 | - 0 0 1 7 3 1 | - 0 0 5 2 9 3 | - 0 1 5 5 9 7 | - 0 0 1 9 6 6 | 0 0 2 7 2 1 | 0 1 2 7 2 6 | - 0 0 9 0 5 5\",\n",
      "  \"target_text\": \"- 0 0 1 8 6 5\"\n",
      "}\n",
      "\n",
      "Example Delphyne-style sample for VTI_ret:\n",
      "{\n",
      "  \"input_text\": \"-0.017182 -0.009799 0.011933 0.01764 -0.00829 -0.007124 -0.002296 -0.005466 -0.010125 0.013248 0.001442 0.004512 0.015195 -0.004519 0.004161 -0.011677 -0.01353 0.009563 -0.013586 0.011251 0.015347 -0.003495 0.010996 -0.003001 -0.004984 0.010208 0.000468 0.009632 0.004724 0.001567 0.000552 -0.000276 0.005613 -0.000091 0.002288 -0.000365 -0.000639 -0.003565 0.006146 -0.004103 -0.004028 0.001563 -0.013857 0.003722 -0.015205 -0.000753 0.012531 -0.005583 0.012539 -0.001941 0.011481 -0.00357 0.00836 -0.001731 -0.005293 -0.015597 -0.001966 0.002721 0.012726 -0.009055\",\n",
      "  \"target_text\": \"-0.001865\"\n",
      "}\n",
      "Processing IVV_ret...\n",
      "  ✓ Saved dataset_gruver_IVV_ret.jsonl  (1702 samples)\n",
      "  ✓ Saved dataset_delphyne_IVV_ret.jsonl  (1702 samples)\n",
      "\n",
      "Example Gruver-style sample for IVV_ret:\n",
      "{\n",
      "  \"input_text\": \"- 0 1 7 5 6 0 | - 0 0 9 0 1 0 | 0 1 2 3 7 1 | 0 1 7 8 6 4 | - 0 0 8 4 3 8 | - 0 0 7 5 8 6 | - 0 0 2 5 9 7 | - 0 0 6 0 4 3 | - 0 0 9 3 9 1 | 0 1 2 8 2 3 | 0 0 2 4 6 3 | 0 0 4 9 1 4 | 0 1 4 6 7 0 | - 0 0 5 3 5 0 | 0 0 2 6 6 5 | - 0 1 3 4 3 4 | - 0 1 2 9 3 1 | 0 0 9 5 7 7 | - 0 1 2 6 8 1 | 0 1 2 1 4 7 | 0 1 4 2 1 5 | - 0 0 3 5 4 0 | 0 1 0 4 6 4 | - 0 0 3 2 2 7 | - 0 0 4 3 0 1 | 0 1 0 8 2 2 | 0 0 0 4 8 0 | 0 0 9 3 1 0 | 0 0 4 5 1 6 | 0 0 1 7 9 8 | - 0 0 0 1 8 9 | - 0 0 0 8 0 3 | 0 0 6 1 0 0 | - 0 0 0 3 2 9 | 0 0 3 0 0 9 | - 0 0 0 7 5 0 | - 0 0 1 1 2 6 | - 0 0 3 2 8 8 | 0 0 6 3 6 1 | - 0 0 4 4 9 5 | - 0 0 4 1 8 6 | 0 0 1 0 3 9 | - 0 1 3 9 2 0 | 0 0 4 1 6 3 | - 0 1 6 3 4 5 | - 0 0 2 1 3 2 | 0 1 2 4 7 7 | - 0 0 6 1 3 8 | 0 1 3 8 4 7 | - 0 0 3 3 7 9 | 0 1 1 7 9 4 | - 0 0 4 2 9 4 | 0 0 8 8 1 5 | - 0 0 1 6 4 5 | - 0 0 6 2 5 8 | - 0 1 4 1 7 0 | - 0 0 2 4 6 1 | 0 0 2 0 3 2 | 0 1 2 1 6 8 | - 0 0 8 5 3 9\",\n",
      "  \"target_text\": \"- 0 0 3 1 2 7\"\n",
      "}\n",
      "\n",
      "Example Delphyne-style sample for IVV_ret:\n",
      "{\n",
      "  \"input_text\": \"-0.01756 -0.00901 0.012371 0.017864 -0.008438 -0.007586 -0.002597 -0.006043 -0.009391 0.012823 0.002463 0.004914 0.01467 -0.00535 0.002665 -0.013434 -0.012931 0.009577 -0.012681 0.012147 0.014215 -0.00354 0.010464 -0.003227 -0.004301 0.010822 0.00048 0.00931 0.004516 0.001798 -0.000189 -0.000803 0.0061 -0.000329 0.003009 -0.00075 -0.001126 -0.003288 0.006361 -0.004495 -0.004186 0.001039 -0.01392 0.004163 -0.016345 -0.002132 0.012477 -0.006138 0.013847 -0.003379 0.011794 -0.004294 0.008815 -0.001645 -0.006258 -0.01417 -0.002461 0.002032 0.012168 -0.008539\",\n",
      "  \"target_text\": \"-0.003127\"\n",
      "}\n",
      "Processing ARKK_ret...\n",
      "  ✓ Saved dataset_gruver_ARKK_ret.jsonl  (1702 samples)\n",
      "  ✓ Saved dataset_delphyne_ARKK_ret.jsonl  (1702 samples)\n",
      "\n",
      "Example Gruver-style sample for ARKK_ret:\n",
      "{\n",
      "  \"input_text\": \"- 0 2 4 0 9 5 | - 0 0 3 7 5 9 | 0 0 4 5 8 9 | 0 2 2 3 3 5 | - 0 0 8 4 4 1 | 0 0 9 0 1 4 | - 0 0 7 9 4 0 | - 0 0 3 0 0 2 | - 0 2 2 5 7 9 | 0 0 6 6 7 3 | 0 1 4 2 7 8 | 0 1 8 1 0 0 | 0 1 3 7 2 8 | 0 0 4 9 6 9 | 0 0 5 8 1 7 | - 0 1 4 9 4 0 | - 0 0 4 4 0 3 | 0 0 1 9 6 5 | - 0 0 7 3 5 6 | 0 0 6 2 7 5 | - 0 0 6 7 2 7 | 0 1 1 3 6 9 | 0 1 8 5 7 3 | - 0 0 2 3 0 3 | - 0 0 5 4 8 3 | 0 0 8 3 1 8 | 0 0 8 4 4 1 | 0 0 7 5 1 5 | 0 1 2 5 5 7 | - 0 0 5 1 2 8 | 0 0 1 4 0 6 | 0 0 7 9 5 5 | 0 0 6 6 8 5 | - 0 0 9 4 0 8 | - 0 0 2 7 0 0 | 0 0 0 3 7 3 | 0 0 9 7 9 9 | - 0 0 6 0 0 7 | - 0 0 0 5 1 2 | - 0 0 7 3 9 5 | - 0 0 5 6 7 0 | 0 0 6 2 6 8 | - 0 1 8 0 7 8 | - 0 0 7 9 1 8 | - 0 1 0 6 7 3 | 0 0 4 2 2 8 | 0 0 0 7 2 6 | - 0 0 3 0 9 5 | 0 0 8 9 2 5 | 0 0 3 3 6 6 | - 0 0 3 3 5 4 | 0 1 4 4 2 3 | 0 1 0 9 0 1 | - 0 0 1 8 7 5 | 0 0 0 0 0 0 | - 0 2 2 5 4 6 | - 0 0 0 9 6 1 | - 0 0 1 4 4 3 | 0 1 1 5 6 1 | - 0 0 7 8 5 7\",\n",
      "  \"target_text\": \"- 0 1 6 0 7 9\"\n",
      "}\n",
      "\n",
      "Example Delphyne-style sample for ARKK_ret:\n",
      "{\n",
      "  \"input_text\": \"-0.024095 -0.003759 0.004589 0.022335 -0.008441 0.009014 -0.00794 -0.003002 -0.022579 0.006673 0.014278 0.0181 0.013728 0.004969 0.005817 -0.01494 -0.004403 0.001965 -0.007356 0.006275 -0.006727 0.011369 0.018573 -0.002303 -0.005483 0.008318 0.008441 0.007515 0.012557 -0.005128 0.001406 0.007955 0.006685 -0.009408 -0.0027 0.000373 0.009799 -0.006007 -0.000512 -0.007395 -0.00567 0.006268 -0.018078 -0.007918 -0.010673 0.004228 0.000726 -0.003095 0.008925 0.003366 -0.003354 0.014423 0.010901 -0.001875 0 -0.022546 -0.000961 -0.001443 0.011561 -0.007857\",\n",
      "  \"target_text\": \"-0.016079\"\n",
      "}\n",
      "\n",
      "All datasets built successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# ============================\n",
    "# LOAD RETURN SERIES\n",
    "# ============================\n",
    "\n",
    "df = pd.read_csv(\"market_features_master.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "# Select the return columns for LLM training\n",
    "return_cols = [\n",
    "    \"SP500_ret\", \"NASDAQ_ret\", \"SPY_ret\", \n",
    "    \"QQQ_ret\", \"VTI_ret\", \"IVV_ret\", \"ARKK_ret\"\n",
    "]\n",
    "\n",
    "# Combine all returns into a single long sequence (as in Gruver/Delphyne)\n",
    "# series = df[return_cols].stack().dropna()\n",
    "# values = series.values  # numpy array of floats\n",
    "\n",
    "# ============================\n",
    "# PARAMETERS\n",
    "# ============================\n",
    "\n",
    "WINDOW = 60   # past 60 timesteps → predict next\n",
    "\n",
    "\n",
    "# ============================\n",
    "# DIGIT-LEVEL TOKENIZER (GRUVER)\n",
    "# ============================\n",
    "\n",
    "def digit_tokenize(x):\n",
    "    \"\"\"\n",
    "    Convert numeric value into digit tokens (cap at 6 decimal places):\n",
    "    0.0123 → \"0 1 2 3 0 0\"\n",
    "    0.123456 → \"1 2 3 4 5 6\"\n",
    "    1.5   → \"1 5 0 0 0 0 0\"\n",
    "    -0.5   → \"- 5 0 0 0 0 0\"\n",
    "    \"\"\"\n",
    "    # s = \"{:.6f}\".format(x)   # fixed length\n",
    "    # s = s.rstrip(\"0\")        # remove trailing zeros\n",
    "    # if s.endswith(\".\"):\n",
    "    #     s += \"0\"\n",
    "\n",
    "    # tokens = []\n",
    "    # for ch in s:\n",
    "    #     if ch == '.':\n",
    "    #         tokens.append(\".\")\n",
    "    #     elif ch == '-':\n",
    "    #         tokens.append(\"-\")\n",
    "    #     else:\n",
    "    #         tokens.append(ch)\n",
    "    # return \" \".join(tokens)\n",
    "    \n",
    "    neg = x < 0\n",
    "    x = abs(x)\n",
    "\n",
    "    # extract decimal digits\n",
    "    dec = f\"{x:.6f}\".split(\".\")[1]   # always 6 digits\n",
    "\n",
    "    # remove trailing zeros? No — we KEEP & PAD to exactly 6 digits\n",
    "    digits = list(dec[:6])           # ensure max 6\n",
    "\n",
    "    # negative sign should be its own token:\n",
    "    if neg:\n",
    "        return \"- \" + \" \".join(digits)\n",
    "    else:\n",
    "        return \" \".join(digits)\n",
    "\n",
    "\n",
    "# ============================\n",
    "# SIMPLE NUMERIC TOKENIZER (DELPHYNE)\n",
    "# ============================\n",
    "\n",
    "def numeric_tokenize(x):\n",
    "    \"\"\"\n",
    "    Convert number into a single text token:\n",
    "    0.0123 → \"0.0123\"\n",
    "    \"\"\"\n",
    "    return \"{:.6f}\".format(x).rstrip(\"0\").rstrip(\".\")\n",
    "\n",
    "\n",
    "# ============================\n",
    "# MAIN LOOP – ONE OUTPUT PER SERIES\n",
    "# ============================\n",
    "\n",
    "for col in return_cols:\n",
    "\n",
    "    print(f\"Processing {col}...\")\n",
    "\n",
    "    # extract one series\n",
    "    series = df[col].dropna().values\n",
    "\n",
    "    # ---------------------------\n",
    "    # BUILD GRUVER DATASET\n",
    "    # ---------------------------\n",
    "    gruver_samples = []\n",
    "\n",
    "    for i in range(len(series) - WINDOW):\n",
    "        input_seq = series[i : i + WINDOW]\n",
    "        target = series[i + WINDOW]\n",
    "\n",
    "        tokenized_input = \" | \".join(digit_tokenize(v) for v in input_seq)\n",
    "        tokenized_target = digit_tokenize(target)\n",
    "\n",
    "        gruver_samples.append({\n",
    "            \"input_text\": tokenized_input,\n",
    "            \"target_text\": tokenized_target\n",
    "        })\n",
    "\n",
    "    out_file = f\"dataset_gruver_{col}.jsonl\"\n",
    "    with open(out_file, \"w\") as f:\n",
    "        for item in gruver_samples:\n",
    "            f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "    print(f\"  ✓ Saved {out_file}  ({len(gruver_samples)} samples)\")\n",
    "\n",
    "\n",
    "    # ---------------------------\n",
    "    # BUILD DELPHYNE DATASET\n",
    "    # ---------------------------\n",
    "    delphyne_samples = []\n",
    "\n",
    "    for i in range(len(series) - WINDOW):\n",
    "        input_seq = series[i : i + WINDOW]\n",
    "        target = series[i + WINDOW]\n",
    "\n",
    "        input_str = \" \".join(numeric_tokenize(v) for v in input_seq)\n",
    "        target_str = numeric_tokenize(target)\n",
    "\n",
    "        delphyne_samples.append({\n",
    "            \"input_text\": input_str,\n",
    "            \"target_text\": target_str\n",
    "        })\n",
    "\n",
    "    out_file = f\"dataset_delphyne_{col}.jsonl\"\n",
    "    with open(out_file, \"w\") as f:\n",
    "        for item in delphyne_samples:\n",
    "            f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "    print(f\"  ✓ Saved {out_file}  ({len(delphyne_samples)} samples)\")\n",
    "\n",
    "\n",
    "    print(\"\\nExample Gruver-style sample for \" + col + \":\")\n",
    "    print(json.dumps(gruver_samples[0], indent=2))\n",
    "\n",
    "    print(\"\\nExample Delphyne-style sample for \" + col + \":\")\n",
    "    print(json.dumps(delphyne_samples[0], indent=2))\n",
    "\n",
    "print(\"\\nAll datasets built successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================\n",
    "# ARCHIVE: SINGLE DATASET FOR ALL SERIES\n",
    "# ============================\n",
    "\n",
    "# ============================\n",
    "# BUILD DATASET 1 (GRUVER)\n",
    "# ============================\n",
    "\n",
    "# gruver_samples = []\n",
    "\n",
    "# for i in range(len(values) - WINDOW):\n",
    "#     input_seq = values[i : i + WINDOW]\n",
    "#     target = values[i + WINDOW]\n",
    "\n",
    "#     # Tokenize each element\n",
    "#     tokenized_input = \" | \".join(digit_tokenize(v) for v in input_seq)\n",
    "#     tokenized_target = digit_tokenize(target)\n",
    "\n",
    "#     gruver_samples.append({\n",
    "#         \"input_text\": tokenized_input,\n",
    "#         \"target_text\": tokenized_target\n",
    "#     })\n",
    "\n",
    "# # Save\n",
    "# with open(\"dataset_gruver_digit.jsonl\", \"w\") as f:\n",
    "#     for item in gruver_samples:\n",
    "#         f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "# print(f\"Saved Gruver-style dataset with {len(gruver_samples)} samples.\")\n",
    "\n",
    "\n",
    "# ============================\n",
    "# BUILD DATASET 2 (DELPHYNE)\n",
    "# ============================\n",
    "\n",
    "\n",
    "# delphyne_samples = []\n",
    "\n",
    "# for i in range(len(values) - WINDOW):\n",
    "#     input_seq = values[i : i + WINDOW]\n",
    "#     target = values[i + WINDOW]\n",
    "\n",
    "#     # Tokenize numerically\n",
    "#     input_str = \" \".join(numeric_tokenize(v) for v in input_seq)\n",
    "#     target_str = numeric_tokenize(target)\n",
    "\n",
    "#     delphyne_samples.append({\n",
    "#         \"input_text\": input_str,\n",
    "#         \"target_text\": target_str\n",
    "#     })\n",
    "\n",
    "# # Save\n",
    "# with open(\"dataset_delphyne_numeric.jsonl\", \"w\") as f:\n",
    "#     for item in delphyne_samples:\n",
    "#         f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "# print(f\"Saved Delphyne-style dataset with {len(delphyne_samples)} samples.\")\n",
    "\n",
    "\n",
    "# ============================\n",
    "# PREVIEW SAMPLES\n",
    "# ============================\n",
    "\n",
    "# print(\"\\nExample Gruver-style sample:\")\n",
    "# print(json.dumps(gruver_samples[0], indent=2))\n",
    "\n",
    "# print(\"\\nExample Delphyne-style sample:\")\n",
    "# print(json.dumps(delphyne_samples[0], indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
